{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRELIMINARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have as our original function:\n",
    "\n",
    "$$f(x) =  x^3 - 3x^2 -45x + 40  $$\n",
    "\n",
    "To find the optimal points, we need to solve:\n",
    "\n",
    "$$f'(x) = \\frac{\\delta y}{\\delta x} =  0 $$\n",
    "\n",
    "Since we are doing an optimization, we will apply Halley's method to the first derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE GENERAL OPTIMIZATION ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general optimization process is characterized by iteratively an initial value to approach a critical point. It can be summarized as follows:\n",
    "    \n",
    "1.  Choose an initial value for the function which roots we are trying to find.\n",
    "2.  We update this initial value using a formula that differs depending on the method we are applying.\n",
    "3.  Use the updated value and calculate the value of our function.\n",
    "4.  Repeat steps 2 - 3 until we get our function (the output to step 3) to be equal to zero (0) or to a value significantly close to a chosen threshold (referred to by resources as epsilon ($\\epsilon$))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HALLEY'S METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the prior section, we need to determine the formula for updating our initial value for Halley's method. The formula is given in different versions, however, I find this one easier to code:\n",
    "\n",
    "$$x_{n+1} = x_n - \\frac{2f(x_n)f'(x_n)}{2[f'(x_n)]^2 - f(x_n)f''(x_n)} $$\n",
    "\n",
    "where $x_{n+1}$ = the updated value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the update function requires as to estimate, not only the first but also the second derivative of the function which roots we are trying to find. That means, estimating the first and second derivative of the first derivative of the original function. These are equivalently the second and third derivative of the original function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have:\n",
    "\n",
    "$$\\frac{\\delta y}{\\delta x} = 3x^2 - 6x -45 $$\n",
    "\n",
    "$$\\frac{\\delta y^2}{\\delta^2 x} = 6x -6$$\n",
    "\n",
    "and lastly, \n",
    "\n",
    "$$\\frac{\\delta y^3}{\\delta^3 x} = 6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So applying our general process and the formula for updating Halley's method, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Root Finding - This is the first derivative of the original function\n",
    "def f_0(x):\n",
    "    return 3*x**2 - 6*x -45\n",
    "\n",
    "#First Derivative for Root Function\n",
    "def f_1(x):\n",
    "    return 6*x - 6\n",
    "\n",
    "#Second Derivative for Root Function\n",
    "def f_2(x):\n",
    "    return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6229394652999\n",
      "7.380356937422013\n",
      "5.09764457132621\n",
      "5.000014026810398\n",
      "5.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "initial_value = 50\n",
    "\n",
    "#Initialize to count total iterations\n",
    "iterations = 0\n",
    "\n",
    "#Initialize a container for target variable\n",
    "x_curr = initial_value\n",
    "\n",
    "#Setting epsilon - threshold (0.00001)\n",
    "epsilon = 0.00001\n",
    "\n",
    "f = f_0(x_curr)\n",
    "\n",
    "\n",
    "while (abs(f) > epsilon):\n",
    "    \n",
    "    #Calculate function values\n",
    "    f = f_0(x_curr)\n",
    "    f_prime = f_1(x_curr)\n",
    "    f_double_prime = f_2(x_curr)\n",
    "    \n",
    "    #Update the value of the variable as long as the threshold has not been met\n",
    "    x_curr = x_curr - (2*f*f_prime)/(2*f_prime**2 - f*f_double_prime )\n",
    "    \n",
    "    #Update Iterations Count\n",
    "    iterations += 1\n",
    "    print(x_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROOT-FINDING FUNCTION USING HALLEY'S METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create a general function for Halley's method that can incorporate other nice features for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halleys_method(root_func, first_prime, second_prime, eps, initial):\n",
    "    ''' Finds a root of a function using Halley's method.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "        root_func (function)    : The function which roots are being solved\n",
    "        first_prime (function)  : The first derivative of the root_func parameter\n",
    "        second_prime (function) : The second derivative of the root_func parameter\n",
    "        eps (float)             : Error threshold value close enough to zero (0)\n",
    "        initial (float)         : Initial value of the variable\n",
    "        \n",
    "    Returns:\n",
    "        The final value of the variable for which a local optimal value is found.\n",
    "    '''\n",
    "    #Initialize to count total iterations\n",
    "    iterations = 0\n",
    "\n",
    "    ##Initialize a container for target variable\n",
    "    x_curr = initial\n",
    "    \n",
    "    #Initialize First Function Value\n",
    "    f = root_func(x_curr)\n",
    "    \n",
    "    #Update the variable\n",
    "    while (abs(f) > eps):\n",
    "    \n",
    "        #Calculate function values\n",
    "        f = root_func(x_curr)\n",
    "        f_prime = first_prime(x_curr)\n",
    "        f_double_prime = second_prime(x_curr)\n",
    "\n",
    "        #Update the value of the variable as long as the threshold has not been met\n",
    "        x_curr = x_curr - (2*f*f_prime)/(2*f_prime**2 - f*f_double_prime )\n",
    "\n",
    "        #Update Iterations Count\n",
    "        iterations += 1\n",
    "    \n",
    "    print(f\"SUCCESS! Algorithm converged after {iterations} iterations. An optimum can be found at point: \")\n",
    "    \n",
    "    return x_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS! Algorithm converged after 6 iterations. An optimum can be found at point: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halleys_method(root_func=f_0, \n",
    "               first_prime=f_1, \n",
    "               second_prime=f_2, \n",
    "               eps=0.00001, \n",
    "               initial=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING BUILT-IN FUNCTION IN SCIPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those, however, who are after a more convenient way to use Halley's method, we can utilize the one available in Scipy. Using the functions we have defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import newton\n",
    "\n",
    "newton(func=f_0,x0=50,fprime=f_1,fprime2=f_2, tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL REMARKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function we developed above is pretty good for most nonlinear optimization problems. As with most nonlinear optimization algorithm, Halley's method converges to what we call as a \"local optimum\". This is different from the \"global optimum\" which is the absolute optimum point for the entire equation.\n",
    "\n",
    "Depending on your choice of initial value, the algorithm converges to either a local or global optimum, usually whichever is closer to the initial value. As such, try the algorithm above with an extreme negative initial value and an extreme positive value. \n",
    "\n",
    "Lastly, Halley's method is known to converge pretty quickly and is one of the clear advantage it has over other optimization method. Trying on an extreme value, one can see how quickly the algorithm hovers around a local optimum pretty quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
